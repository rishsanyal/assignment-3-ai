{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load in nltk.book. Consider text1 ('Moby Dick'), text2 ('Sense and Sensibility'), text3 ('Book of Genesis'), text7('Wall Street Journal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\n",
      "Curr Word Target -> great\n",
      "good whale long sea vast whole other living large dead small more much\n",
      "mighty such same sperm last old before\n",
      "\n",
      "\n",
      "long a good much well some the large this young such any strong quiet\n",
      "happy to his her which it\n",
      "\n",
      "\n",
      "not found there be good second one se tree third fourth man put gold\n",
      "bdellium stone euphrates thereof taken woman\n",
      "\n",
      "\n",
      "good and to high three expected special october last strong greater\n",
      "hefty low unique hierarchical aircraft tight massive\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "Curr Word Target -> king\n",
      "whale ship sea boat man line pequod water head captain time crew rope\n",
      "harpooneer cry world lord day monster land\n",
      "\n",
      "\n",
      "No matches\n",
      "\n",
      "\n",
      "well men captain beginning god and face spirit waters good day\n",
      "firmament midst place land gathering herb fruit tree days\n",
      "\n",
      "\n",
      "No matches\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "Curr Word Target -> country\n",
      "boat crew body whale vessel man ship captain difference father\n",
      "doubloon heart hand dutch french will devil have whales book\n",
      "\n",
      "\n",
      "house world room latter matter other time place subject others past\n",
      "case truth morning day better fire letter window weather\n",
      "\n",
      "\n",
      "lord sight children house people firstborn waters day firmament place\n",
      "land cattle name woman father mother wife head hand way\n",
      "\n",
      "\n",
      "company president market government issue region agency period senate\n",
      "economy world stock law constitution and year information early plant\n",
      "contract\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "Curr Word Target -> fear\n",
      "thought am see whales men doubt love do him was all it hand whale more\n",
      "english will have said no\n",
      "\n",
      "\n",
      "hope think wish believe it had him one desire promise thought me know\n",
      "want style felt hear edward doubt sense\n",
      "\n",
      "\n",
      "do beginning god face spirit waters saw good day firmament midst place\n",
      "land gathering bring herb fruit tree days stars\n",
      "\n",
      "\n",
      "the board a chairman form percentage deaths unit journal risk\n",
      "institute university type billion number total rate support argue\n",
      "class\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "Curr Word Target -> love\n",
      "sea man it ship by him hand them whale view ships land me life death\n",
      "water way head nature fear\n",
      "\n",
      "\n",
      "affection sister heart mother time see town life it dear elinor\n",
      "marianne me word family her him do regard head\n",
      "\n",
      "\n",
      "went drank earth darkness morning se them give nig hath man had thus\n",
      "not took keep die call sle woman\n",
      "\n",
      "\n",
      "No matches\n",
      "\n",
      "\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consider text1 ('Moby Dick'), text2 ('Sense and Sensibility'), text3 ('Book of Genesis'), text7('Wall Street Journal')\n",
    "\n",
    "# Write a loop that displays, for each text, which words are similar to:\n",
    "\n",
    "#     'great',\n",
    "#     'king',\n",
    "#     'country',\n",
    "#     'fear',\n",
    "#     'love'\n",
    "\n",
    "\n",
    "similar_words_targets = ['great', 'king', 'country', 'fear', 'love']\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "TEXTBOOK_PREFIX = 'text'\n",
    "TEXTBOOK_SUFFIXES = [1, 2, 3, 7]\n",
    "\n",
    "for propertyName in dir(nltk.book):\n",
    "    if propertyName.startswith(TEXTBOOK_PREFIX) and propertyName[-1].isdigit() and int(propertyName[-1]) in TEXTBOOK_SUFFIXES:\n",
    "        all_texts.append(getattr(nltk.book, propertyName))\n",
    "\n",
    "for currWord in similar_words_targets:\n",
    "    print(\"-\"*10 + \"\\n\")\n",
    "    print(\"Curr Word Target -> %s\" %(currWord))\n",
    "    for currText in all_texts:\n",
    "       currText.similar(currWord)\n",
    "       print(\"\\n\")\n",
    "    print(\"-\"*10 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long , from one to the top - mast , and no coffin and went out a sea\n",
      "captain -- this peaking of the whales . , so as to preserve all his\n",
      "might had in former years abounding with them , they toil with their\n",
      "lances , strange tales\n",
      "knew , had by this remembrance , and if , by rapid degrees , so long .\n",
      ", she could live without one another , and in her rambles . at least\n",
      "the last evening of a brother , could you know , from the first .\n",
      "Dashwood ? this\n",
      "laid by her , and said unto Cain , Where art thou , and said , Go to ,\n",
      "I will not do it for ten ' s sons ; we dreamed each man according to\n",
      "their generatio the firstborn said unto Laban , Because I said , Nay ,\n",
      "has *-2 to close at 2645.90 in moderate trading , a large addition or\n",
      "subtraction to a new public spirit for school betterment . *-1 to beat\n",
      "the tests themselves that critics say 0 Columbia 's junk problems\n",
      "*T*-1 . Sea Containers is still : ` * Buy , '\n"
     ]
    }
   ],
   "source": [
    "# Write a loop that, for each text, generates a 50-token random sequence.\n",
    "\n",
    "## Question, is this it?\n",
    "for i in all_texts:\n",
    "    i.generate(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews\n",
      "[(',', 42448), ('the', 41471), ('.', 33714), ('a', 20196), ('and', 19896), ('of', 18636), ('to', 16517), (\"'\", 15268), ('is', 14059), ('in', 11725)]\n",
      "Negative Reviews\n",
      "[(',', 35269), ('the', 35058), ('.', 32162), ('a', 17910), ('and', 15680), ('of', 15487), ('to', 15420), (\"'\", 15317), ('is', 11136), ('in', 10097)]\n"
     ]
    }
   ],
   "source": [
    "# Now let's make two Frequency Distributions.\n",
    "# We'll use the movie_reviews corpus. \n",
    "# Construct one Frequency Distribution that counts all of the words in the positive reviews, and one that counts all of the words in the negative reviews. \n",
    "# Print the 10 most common words in each distribution.\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "pos_freq_dist = nltk.FreqDist(movie_reviews.words(categories='pos'))\n",
    "neg_freq_dist = nltk.FreqDist(movie_reviews.words(categories='neg'))\n",
    "\n",
    "print(\"Positive Reviews\")\n",
    "print(pos_freq_dist.most_common(10))\n",
    "print(\"Negative Reviews\")\n",
    "print(neg_freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews\n",
      "[('film', 5232), ('one', 3052), ('movie', 2528), ('like', 1802), ('good', 1248), ('story', 1247), ('time', 1243), ('also', 1200), ('even', 1179), ('well', 1123)]\n",
      "Negative Reviews\n",
      "[('film', 4287), ('movie', 3246), ('one', 2801), ('like', 1888), ('even', 1386), ('time', 1168), ('good', 1163), ('would', 1090), ('get', 1052), ('bad', 1035)]\n"
     ]
    }
   ],
   "source": [
    "# There's a lot of noise in our data. As in assignment1, \n",
    "# update your code to remove stopwords, non-words, and convert everything to \n",
    "# lower case. Does that help to distinguish between positive and negative reviews?\n",
    "\n",
    "from nltk.corpus import stopwords, words\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "english_words = set(words.words())\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([ch for ch in text if ch not in punctuation])\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = ' '.join([word for word in text.split() if word in english_words])\n",
    "    return text\n",
    "\n",
    "pos_freq_dist = nltk.FreqDist([clean_text(word) for word in movie_reviews.words(categories='pos')])\n",
    "neg_freq_dist = nltk.FreqDist([clean_text(word) for word in movie_reviews.words(categories='neg')])\n",
    "\n",
    "pos_freq_dist.pop('')\n",
    "neg_freq_dist.pop('')\n",
    "\n",
    "print(\"Positive Reviews\")\n",
    "print(pos_freq_dist.most_common(10))\n",
    "\n",
    "print(\"Negative Reviews\")\n",
    "print(neg_freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: neg\n",
      "[('', 502967), ('film', 4287), ('movie', 3246), ('one', 2801), ('like', 1888), ('even', 1386), ('time', 1168), ('good', 1163), ('would', 1090), ('get', 1052), ('bad', 1035)]\n",
      "Category: pos\n",
      "[('', 557007), ('film', 5232), ('one', 3052), ('movie', 2528), ('like', 1802), ('good', 1248), ('story', 1247), ('time', 1243), ('also', 1200), ('even', 1179), ('well', 1123)]\n"
     ]
    }
   ],
   "source": [
    "# Rather than keeping our distributions in two separate data structures, let's use a ConditionalFrequencyDistribution. (see Chapter 3)\n",
    "# Add a loop that iterates through the ConditionalFrequencyDistribution and prints the 10 most common words for each category.\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (category, word)\n",
    "    for category in movie_reviews.categories()\n",
    "    for word in [clean_text(word) for word in movie_reviews.words(categories=category)])\n",
    "\n",
    "for category in movie_reviews.categories():\n",
    "    print(\"Category: %s\" %(category))\n",
    "    print(cfd[category].most_common(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
